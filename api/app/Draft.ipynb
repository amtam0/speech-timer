{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce7fc47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "from speechbrain.pretrained import EncoderASR, EncoderDecoderASR, EncoderClassifier\n",
    "from text_to_num import alpha2digit\n",
    "import base64\n",
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd12a35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 hours'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha2digit(\"two hours\", \"en\",\n",
    "           relaxed=False, signed=True, ordinal_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c73a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_flare(model, TEXT_test):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    sentence = Sentence(TEXT_test)\n",
    "    # predict the tags\n",
    "    model.predict(sentence)\n",
    "    result_dict = sentence.to_dict(\"ner\")\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def doc_to_spans_flare(doc):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    scores = []\n",
    "    entities = []\n",
    "    results = []\n",
    "    zipped = []\n",
    "    predictions = doc[\"entities\"]\n",
    "    for prediction in predictions:\n",
    "        if not prediction:\n",
    "            continue\n",
    "        spans.append({\n",
    "            'from_name': 'label',\n",
    "            'to_name': 'text',\n",
    "            'type': 'labels',\n",
    "            'value': {\n",
    "                'start': prediction[\"start_pos\"],\n",
    "                'end': prediction[\"end_pos\"],\n",
    "                'text': prediction[\"text\"],\n",
    "                'labels': [str(prediction[\"labels\"][0]).split()[0]],\n",
    "#                 'score': [str(prediction[\"labels\"][0]).split()[1].strip(\"()\")]\n",
    "            }\n",
    "        })\n",
    "        scores.append(float(str(prediction[\"labels\"][0]).split()[1].strip(\"()\")))\n",
    "        entities.append(str(prediction[\"labels\"][0]).split()[0])\n",
    "        results.append(prediction[\"text\"])\n",
    "    final_dict = {#\"spans\":spans,\n",
    "                 \"entities\":entities,\n",
    "                 \"scores\":scores,\n",
    "                 \"result\":results,\n",
    "                 \"zipped\":[list(a) for a in zip(results, entities, scores)]}\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "def speech_ner(wav_file_path=\"output.wav\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    raw_text = asr_model.transcribe_file(wav_file_path)\n",
    "    print(raw_text)\n",
    "    digit_text = alpha2digit(raw_text,\n",
    "                \"fr\", relaxed=True, signed=False, ordinal_threshold=10).lower()\n",
    "    print(digit_text)\n",
    "    #alpha2digit bug\n",
    "    digit_text = digit_text.replace(\"une heure\",\"1 heure\").replace(\"une minute\",\"1 minute\")\n",
    "    return doc_to_spans_flare(predict_flare(tagger, digit_text))\n",
    "\n",
    "def speech_ner_fr(wav_file_path=\"output.wav\"): #NEW\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    raw_text = asr_model_fr.transcribe_file(wav_file_path)\n",
    "    print(raw_text)\n",
    "    digit_text = alpha2digit(raw_text,\n",
    "                \"fr\", relaxed=True, signed=False, ordinal_threshold=10).lower()\n",
    "    print(digit_text)\n",
    "    #alpha2digit bug\n",
    "    digit_text = digit_text.replace(\"une heure\",\"1 heure\").replace(\"une minute\",\"1 minute\").replace(\"une second\",\"1 seconde\")\n",
    "    return doc_to_spans_flare(predict_flare(tagger_fr, digit_text))\n",
    "\n",
    "def speech_ner_en(wav_file_path=\"output.wav\"): #NEW\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    raw_text = asr_model_en.transcribe_file(wav_file_path)\n",
    "    print(raw_text)\n",
    "    digit_text = alpha2digit(raw_text,\n",
    "                \"en\", relaxed=True, signed=False, ordinal_threshold=10).lower()\n",
    "    print(digit_text)\n",
    "    #alpha2digit bug\n",
    "    digit_text = digit_text.replace(\"one hour\",\"1 hour\").replace(\"one minute\",\"1 minute\").replace(\"one second\",\"1 seconde\")\n",
    "    return doc_to_spans_flare(predict_flare(tagger_en, digit_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecaec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-17 19:37:19,611 loading file /root/.flair/models/speech-timer/19e799904eb07a52c4f62608b81fba30e2aa1c943f4f42d513783fa9380b2839.464f8a698a1df420b87ab0f4ed5b89bf7e2c40ca7c80b15fb570a7d4b2280b03\n",
      "2021-11-17 19:37:30,919 loading file /root/.flair/models/timer-ner-en/55f2e96ed914757a19908cab758790ffdf14750200fe8eeed171da38603006f4.de59a20e65f2d1772de6aa71a900f29502c0c5a1637703041764f4ac2cefc9c5\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "tagger_fr = SequenceTagger.load(\"amtam0/speech-timer\")\n",
    "tagger_en = SequenceTagger.load(\"amtam0/timer-ner-en\")\n",
    "asr_model_fr = EncoderASR.from_hparams(source=\"speechbrain/asr-wav2vec2-commonvoice-fr\",\n",
    "                                    savedir=\"./pretrained_models/asr-wav2vec2-commonvoice-fr\",\n",
    "                                   run_opts={\"device\":\"cuda\"})\n",
    "asr_model_en = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-wav2vec2-commonvoice-en\",\n",
    "                                              savedir=\"./pretrained_models/asr-wav2vec2-commonvoice-en\",\n",
    "                                             run_opts={\"device\":\"cuda\"})\n",
    "lang_model = EncoderClassifier.from_hparams(source=\"speechbrain/lang-id-commonlanguage_ecapa\",\n",
    "                                            savedir=\"./pretrained_models/lang-id-commonlanguage_ecapa\",\n",
    "                                           run_opts={\"device\":\"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b27b7779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc = base64.b64encode(open(\"output1.wav\", \"rb\").read())\n",
    "body_image64 = enc.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be120528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.85 ms, sys: 40.1 ms, total: 44 ms\n",
      "Wall time: 151 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "DATA = {\"body64\":body_image64,\n",
    "\"bmodel_name\": \"\"}\n",
    "img_path = \"out.wav\"\n",
    "with open(img_path, \"wb\") as f:\n",
    "    f.write(base64.b64decode(DATA[\"body64\"]))\n",
    "subprocess.call(\"ffmpeg -i {} -c:a pcm_f32le {} -y\".format(\"output1.wav\", \"out.wav\"),\n",
    "                shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32897800",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "START THREE SETS OF THIRTY MINUTES FORTY FIVE MINUTES BETWEEN EACH SET\n",
      "start 3 sets of 30 minutes 45 minutes between each set\n",
      "CPU times: user 754 ms, sys: 524 Âµs, total: 754 ms\n",
      "Wall time: 228 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entities': ['nb_rounds', 'duration_wt_min', 'duration_br_min'],\n",
       " 'scores': [1.0, 1.0, 1.0],\n",
       " 'result': ['3', '30 minutes', '45 minutes between each set'],\n",
       " 'zipped': [['3', 'nb_rounds', 1.0],\n",
       "  ['30 minutes', 'duration_wt_min', 1.0],\n",
       "  ['45 minutes between each set', 'duration_br_min', 1.0]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "out_prob, score, index, text_lab = lang_model.classify_file('out.wav')\n",
    "if text_lab==[\"French\"]:\n",
    "    print(\"French\")\n",
    "    res = speech_ner_fr(wav_file_path=\"out.wav\")\n",
    "elif text_lab==[\"English\"]:\n",
    "    print(\"English\")\n",
    "    res = speech_ner_en(wav_file_path=\"out.wav\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9198e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# French Example\n",
    "out_prob, score, index, text_lab = lang_model.classify_file('speechbrain/lang-id-commonlanguage_ecapa/example-fr.wav')\n",
    "print(text_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e31f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer_format(_dict):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    hours = int(_dict[\"hours\"])\n",
    "    minutes = int(_dict[\"minutes\"])\n",
    "    seconds = int(_dict[\"seconds\"])\n",
    "\n",
    "    # minutes\n",
    "    sd_minutes = seconds // 60\n",
    "    # remaining seconds\n",
    "    seconds = seconds - (sd_minutes * 60)\n",
    "    # total time\n",
    "    time = '{:02}:{:02}'.format(int(minutes)+sd_minutes+60*hours, int(seconds))\n",
    "    return time\n",
    "\n",
    "def format_result(zipped, entities, Thresh = 0.6):\n",
    "    \n",
    "    wt_dict = {\"seconds\":0,\n",
    "              \"minutes\":0,\n",
    "              \"hours\":0}\n",
    "\n",
    "    br_dict = {\"seconds\":0,\n",
    "              \"minutes\":0,\n",
    "              \"hours\":0}\n",
    "\n",
    "    result_dict = {\"nb_rounds\":\"2\",\n",
    "                   \"wt\":\"01:00\",\n",
    "                  \"br\":\"01:00\"}\n",
    "    Idx_to_rm = []\n",
    "    #control Thresh\n",
    "    for idx,zip_line in enumerate(zipped):\n",
    "        if zip_line[2]<Thresh:\n",
    "            Idx_to_rm.append(idx)\n",
    "    for index in sorted(Idx_to_rm, reverse=True):\n",
    "        del zipped[index]\n",
    "\n",
    "    #control duplicates\n",
    "    if len(entities)!=len(set(entities)):\n",
    "        return result_dict\n",
    "    #     pass\n",
    "    else:\n",
    "        #format\n",
    "        for idx,zip_line in enumerate(zipped):\n",
    "            if zip_line[1]==\"nb_rounds\":\n",
    "                result_dict[\"nb_rounds\"] = re.findall(r'\\d+',zip_line[0])[0]\n",
    "            if \"_wt\" in zip_line[1]:\n",
    "                if zip_line[1]==\"duration_wt_sd\":\n",
    "                    wt_dict[\"seconds\"] = re.findall(r'\\d+',zip_line[0])[0]\n",
    "                elif zip_line[1]==\"duration_wt_min\":\n",
    "                    wt_dict[\"minutes\"] = re.findall(r'\\d+',zip_line[0])[0]\n",
    "                elif zip_line[1]==\"duration_wt_hr\":\n",
    "                    wt_dict[\"hours\"] = re.findall(r'\\d+',zip_line[0])[0]\n",
    "            if \"_br\" in zip_line[1]:\n",
    "                if zip_line[1]==\"duration_br_sd\":\n",
    "                    br_dict[\"seconds\"] = re.findall(r'\\d+',zip_line[0])[0]\n",
    "                elif zip_line[1]==\"duration_br_min\":\n",
    "                    br_dict[\"minutes\"] = re.findall(r'\\d+',zip_line[0])[0]\n",
    "                elif zip_line[1]==\"duration_br_hr\":\n",
    "                    br_dict[\"hours\"] = re.findall(r'\\d+',zip_line[0])[0]\n",
    "        # print(br_dict)\n",
    "        result_dict[\"br\"] = timer_format(br_dict)\n",
    "        result_dict[\"wt\"] = timer_format(wt_dict)\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_result(res[\"zipped\"], res[\"entities\"], Thresh = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA[\"result\"] = res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
